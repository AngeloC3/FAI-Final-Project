{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e608f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'max_n' and 'bucket'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m word2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbanana\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasttext-wiki-news-subwords-300\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Word2Vec model trained on Wikipedia\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_word_similarity_wikipedia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mcalculate_word_similarity_wikipedia\u001b[1;34m(word1, word2, model_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_word_similarity_wikipedia\u001b[39m(word1, word2, model_name):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Load or download the Word2Vec model trained on Wikipedia\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_or_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m# Calculate similarity using Gensim's similarity function\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         similarity \u001b[38;5;241m=\u001b[39m word2vec_model\u001b[38;5;241m.\u001b[39msimilarity(word1, word2)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mdownload_or_load_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m     word2vec_model\u001b[38;5;241m.\u001b[39msave_word2vec_format(model_path, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Load the Word2Vec model if it already exists\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFastTextKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word2vec_model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2062\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit:\n\u001b[0;32m   2061\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(vocab_size, limit)\n\u001b[1;32m-> 2062\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   2065\u001b[0m     _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'max_n' and 'bucket'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc57b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d608f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'max_n' and 'bucket'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m word2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasttext-wiki-news-subwords-300\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Word2Vec model trained on Wikipedia\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_word_similarity_wikipedia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mcalculate_word_similarity_wikipedia\u001b[1;34m(word1, word2, model_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_word_similarity_wikipedia\u001b[39m(word1, word2, model_name):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Load or download the Word2Vec model trained on Wikipedia\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_or_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m# Calculate similarity using Gensim's similarity function\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         similarity \u001b[38;5;241m=\u001b[39m word2vec_model\u001b[38;5;241m.\u001b[39msimilarity(word1, word2)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mdownload_or_load_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m     word2vec_model\u001b[38;5;241m.\u001b[39msave_word2vec_format(model_path, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Load the Word2Vec model if it already exists\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFastTextKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word2vec_model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2062\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit:\n\u001b[0;32m   2061\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(vocab_size, limit)\n\u001b[1;32m-> 2062\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   2065\u001b[0m     _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'max_n' and 'bucket'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb0d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model 'fasttext-wiki-news-subwords-300'...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Supervised fastText models are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m word2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbanana\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasttext-wiki-news-subwords-300\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Word2Vec model trained on Wikipedia\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_word_similarity_wikipedia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mcalculate_word_similarity_wikipedia\u001b[1;34m(word1, word2, model_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_word_similarity_wikipedia\u001b[39m(word1, word2, model_name):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Load or download the Word2Vec model trained on Wikipedia\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_or_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word2vec_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find or load the model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mdownload_or_load_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load the Word2Vec model if it already exists\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading existing model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_facebook_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word2vec_model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py:728\u001b[0m, in \u001b[0;36mload_facebook_model\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_facebook_model\u001b[39m(path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    667\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the model from Facebook's native fasttext `.bin` output file.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \n\u001b[0;32m    669\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    726\u001b[0m \n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_fasttext_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py:808\u001b[0m, in \u001b[0;36m_load_fasttext_format\u001b[1;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the input-hidden weight matrix from Facebook's native fasttext `.bin` output files.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m \n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mopen(model_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m--> 808\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fasttext_bin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m model \u001b[38;5;241m=\u001b[39m FastText(\n\u001b[0;32m    811\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mdim,\n\u001b[0;32m    812\u001b[0m     window\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mws,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m     max_n\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mmaxn,\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    823\u001b[0m model\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mntokens\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\_fasttext_bin.py:345\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fin, encoding, full_model)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_format:\n\u001b[0;32m    343\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(dim\u001b[38;5;241m=\u001b[39mmagic, ws\u001b[38;5;241m=\u001b[39mversion)\n\u001b[1;32m--> 345\u001b[0m raw_vocab, vocab_size, nwords, ntokens \u001b[38;5;241m=\u001b[39m \u001b[43m_load_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate(raw_vocab\u001b[38;5;241m=\u001b[39mraw_vocab, vocab_size\u001b[38;5;241m=\u001b[39mvocab_size, nwords\u001b[38;5;241m=\u001b[39mnwords, ntokens\u001b[38;5;241m=\u001b[39mntokens)\n\u001b[0;32m    348\u001b[0m vectors_ngrams \u001b[38;5;241m=\u001b[39m _load_matrix(fin, new_format\u001b[38;5;241m=\u001b[39mnew_format)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\_fasttext_bin.py:198\u001b[0m, in \u001b[0;36m_load_vocab\u001b[1;34m(fin, new_format, encoding)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Vocab stored by [Dictionary::save](https://github.com/facebookresearch/fastText/blob/master/src/dictionary.cc)\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nlabels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupervised fastText models are not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m words for fastText model from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, vocab_size, fin\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    201\u001b[0m ntokens \u001b[38;5;241m=\u001b[39m _struct_unpack(fin, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@q\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# number of tokens\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Supervised fastText models are not supported"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba2caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "def download_and_save_fasttext_wikipedia_model(model_name, save_path):\n",
    "    # Download the FastText model trained on Wikipedia\n",
    "    model = gensim.downloader.load(model_name)\n",
    "    \n",
    "    # Save the FastText model in a Gensim-compatible format\n",
    "    model.save(save_path)\n",
    "\n",
    "# Example usage\n",
    "model_name = \"fasttext-wiki-news-subwords-300\"\n",
    "save_path = \"fasttext_wiki_model\"\n",
    "download_and_save_fasttext_wikipedia_model(model_name, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89634044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'apple' and 'banana': 0.59\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165db1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7342e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
